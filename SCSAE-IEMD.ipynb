{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IEMD\n",
    "def earth_mover_distance(y_true,y_pre):\n",
    "    return tf.reduce_mean(tf.square(tf.square(tf.cumsum(y_true,axis=-1)-tf.cumsum(y_pre,axis=-1))),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "y_true=[]\n",
    "X_test_all=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCSAE-IEMD\n",
    "for train,test in kfold.split(f,y):\n",
    "    X_train,X_valid=train_test_split(f[train],test_size=DATA_SPLIT_PCT,random_state=SEED)\n",
    "    X_test=f[test]\n",
    "    y_train,y_valid=train_test_split(y_cate[train],test_size=DATA_SPLIT_PCT,random_state=SEED)\n",
    "    y_test=y_cate[test]\n",
    "    X_test_all.append(X_test)\n",
    "   \n",
    "   #Encoder\n",
    "    input_img=Input(shape=(72, 72, 1))\n",
    "\n",
    "    Conv2D_1_encoder=Conv2D(filters = 6, kernel_size = (5, 5), activation='relu', padding='same')\n",
    "\n",
    "    Conv2D_1_decoder=Conv2D(filters=1,kernel_size= (5,5), activation='sigmoid', padding='same')\n",
    "\n",
    "    Conv2D_2_encoder=Conv2D(filters = 16, kernel_size = (5, 5), activation='relu', padding='same')\n",
    "\n",
    "    Conv2D_2_decoder=Conv2D(filters=6, kernel_size=(5, 5), activation='relu', padding='same')\n",
    "\n",
    "    Conv2D_3_encoder=Conv2D(filters = 32, kernel_size = (5, 5), activation='relu', padding='same')\n",
    "\n",
    "    Conv2D_3_decoder=Conv2D(filters = 16, kernel_size = (5, 5), activation='relu', padding='same')\n",
    "#\n",
    "    encoder_1= Conv2D_1_encoder(input_img)\n",
    "\n",
    "    encoder_1= MaxPooling2D(pool_size = (2, 2), padding='same')(encoder_1)\n",
    "\n",
    "    #Decoder\n",
    "    decoder_1= Conv2D(filters=6, kernel_size=(5, 5), activation='relu', padding='same')(encoder_1)\n",
    "\n",
    "    decoder_1= UpSampling2D( (2, 2))(decoder_1)\n",
    "\n",
    "    aux_output_1=Conv2D_1_decoder(decoder_1)\n",
    "    \n",
    "    flatten_1=Flatten()(encoder_1)\n",
    "\n",
    "    dense_1=Dense(512,activation=\"relu\")(flatten_1)\n",
    "\n",
    "    LR_1=Dense(13,activation=\"softmax\",name='LR')(dense_1)\n",
    "\n",
    "    autoencoder_1=Model(inputs=input_img,outputs=[aux_output_1,LR_1,LR_1])\n",
    "\n",
    "    #Encoder\n",
    "    encoder_2=Conv2D_1_encoder(input_img)\n",
    "\n",
    "    encoder_2= MaxPooling2D(pool_size = (2, 2),padding='same')(encoder_2)\n",
    "\n",
    "    encoder_2=Conv2D_2_encoder(encoder_2)\n",
    "\n",
    "    encoder_2= MaxPooling2D(pool_size = (2, 2),padding='same')(encoder_2)\n",
    "\n",
    "    #Decoder\n",
    "    decoder_2= Conv2D(16, (5, 5), activation='relu', padding='same')(encoder_2)\n",
    "\n",
    "    decoder_2= UpSampling2D( (2, 2))(decoder_2)\n",
    "\n",
    "    decoder_2=  Conv2D_2_decoder(decoder_2)\n",
    "\n",
    "    decoder_2= UpSampling2D( (2, 2))(decoder_2)\n",
    "\n",
    "    aux_output_2=Conv2D_1_decoder(decoder_2)\n",
    "\n",
    "    flatten_2=Flatten()(encoder_2)\n",
    "\n",
    "    dense_2=Dense(512,activation=\"relu\")(flatten_2)\n",
    "\n",
    "    LR_2=Dense(13,activation=\"softmax\",name='LR')(dense_2)\n",
    "\n",
    "    autoencoder_2=Model(inputs=input_img,outputs=[aux_output_2,LR_2,LR_2])\n",
    "\n",
    "    #Encoder\n",
    "    encoder_3=Conv2D_1_encoder(input_img)\n",
    "\n",
    "    encoder_3= MaxPooling2D(pool_size = (2, 2),padding='same')(encoder_3)\n",
    "\n",
    "    encoder_3=Conv2D_2_encoder(encoder_3)\n",
    "\n",
    "    encoder_3= MaxPooling2D(pool_size = (2, 2),padding='same')(encoder_3)\n",
    "\n",
    "    encoder_3=Conv2D_3_encoder(encoder_3)\n",
    "\n",
    "    encoder_3= MaxPooling2D(pool_size = (2, 2),padding='same')(encoder_3)\n",
    "\n",
    "    #Decoder\n",
    "    decoder_3= Conv2D(32, (5, 5), activation='relu', padding='same')(encoder_3)\n",
    "\n",
    "    decoder_3= UpSampling2D( (2, 2))(decoder_3)\n",
    "\n",
    "    decoder_3= Conv2D_3_decoder(decoder_3)\n",
    "\n",
    "    decoder_3= UpSampling2D( (2, 2))(decoder_3)\n",
    "\n",
    "    decoder_3=  Conv2D_2_decoder(decoder_3)\n",
    "\n",
    "    decoder_3= UpSampling2D( (2, 2))(decoder_3)\n",
    "\n",
    "    aux_output_3=Conv2D_1_decoder(decoder_3)\n",
    "\n",
    "    flatten_3=Flatten()(encoder_3)\n",
    "\n",
    "    dense_3=Dense(256,activation=\"relu\")(flatten_3)\n",
    "    \n",
    "    dense_3=Dense(64,activation=\"relu\")(dense_3)\n",
    "    \n",
    "    LR_3=Dense(13,activation=\"softmax\",name='LR')(dense_3)\n",
    "\n",
    "    autoencoder_3=Model(inputs=input_img,outputs=[aux_output_3,LR_3,LR_3])\n",
    "    \n",
    "    autoencoder_1.compile(metrics=['accuracy'],\n",
    "                   optimizer=Adam(lr=learning_rate),\n",
    "                    loss_weights= [0.05,1, 0])\n",
    "\n",
    "    history  =autoencoder_1.fit(X_train,\n",
    "                          [X_train, y_train,y_train],\n",
    "                          validation_data=(X_valid,[X_valid,y_valid,y_valid]),\n",
    "                          epochs=nb_epoch,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          verbose=0).history\n",
    "\n",
    "    autoencoder_2.compile(metrics=['accuracy'],\n",
    "                    loss=['mean_squared_error', earth_mover_distance,'categorical_crossentropy'],\n",
    "                    optimizer=Adam(lr=learning_rate),\n",
    "                    loss_weights= [0.05,1, 0])\n",
    "\n",
    "    history  =autoencoder_2.fit(X_train,\n",
    "                          [X_train, y_train,y_train],\n",
    "                          validation_data=(X_valid,[X_valid,y_valid,y_valid]),\n",
    "                          epochs=nb_epoch,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          verbose=0).history\n",
    "\n",
    "    autoencoder_3.compile(metrics=['accuracy'],\n",
    "                    loss=['mean_squared_error', earth_mover_distance,'categorical_crossentropy'],\n",
    "                    optimizer=Adam(lr=learning_rate),\n",
    "                    loss_weights= [0.05,1, 0])\n",
    "    cp = ModelCheckpoint(filepath=\"EEMD-SHAPEALL-loss.hdf5\",monitor='val_LR_1_loss',save_best_only=True,\n",
    "                     verbose = 1,mode='min')\n",
    "    callbacks_list=[cp]\n",
    "\n",
    "    history = autoencoder_3.fit(X_train,\n",
    "                          [X_train, y_train,y_train],\n",
    "                          validation_data=(X_valid,[X_valid,y_valid,y_valid]),\n",
    "                          epochs=nb_epoch,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          verbose=1,\n",
    "                          callbacks=callbacks_list).history\n",
    "    \n",
    "    autoencoder_3.load_weights(\"EEMD-SHAPEALL-loss.hdf5\")\n",
    "\n",
    "\n",
    "#Acc\n",
    "    scores=autoencoder_3.evaluate(X_test,[X_test,y_test,y_test],verbose=1)\n",
    "    y_pred_1=autoencoder_3.predict_generator(X_test)\n",
    "    y_pred_class=np.argmax(y_pred_1[1],axis=1)\n",
    "    y_pred.append(y_pred_class)\n",
    "    y_true_class=np.argmax(y_test,axis=1)\n",
    "    y_true.append(y_true_class)\n",
    "    print(scores[5]*100)\n",
    "    \n",
    "    score.append(scores[5]*100)\n",
    "\n",
    "print( np.mean(score),np.std(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def CM(data, name):\n",
    "    \n",
    "    conf_mx = data\n",
    "\n",
    "\n",
    "    class Percent(float):\n",
    "        def __str__(self):\n",
    "            return '{:.2%}'.format(self)\n",
    "\n",
    "    norm_conf = []\n",
    "    for i in conf_mx:\n",
    "        a = 0\n",
    "        tmp_arr = []\n",
    "        a = sum(i,0)\n",
    "        for j in i:\n",
    "            tmp_arr.append(float(j)/float(a))\n",
    "        norm_conf.append(tmp_arr)\n",
    "\n",
    "\n",
    "    plt.clf()\n",
    "    plt.rcParams['xtick.bottom'] = plt.rcParams['xtick.labelbottom'] = False\n",
    "    plt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = True\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "    plt.rc('xtick', labelsize='25')\n",
    "    plt.rc('ytick', labelsize='25')\n",
    "\n",
    "    rc('font', weight='bold')\n",
    "\n",
    "    fig = plt.figure(figsize=(18,18))\n",
    "\n",
    "    COLOR = 'black'\n",
    "    mpl.rcParams['text.color'] = COLOR  \n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "    ticks_x = ticker.FuncFormatter(lambda x, pos: 'h'+'{0:g}'.format(x+1))\n",
    "    ax.xaxis.set_major_formatter(ticks_x)\n",
    "\n",
    "    ticks_y = ticker.FuncFormatter(lambda x, pos: 'h'+'{0:g}'.format(x+1))\n",
    "    ax.yaxis.set_major_formatter(ticks_y)\n",
    "\n",
    "    ax.set_xticks(np.arange(13))\n",
    "    ax.set_yticks(np.arange(13))\n",
    "\n",
    "    res = ax.imshow(array(norm_conf), cmap=cm.binary, interpolation='nearest')\n",
    "    COLOR = 'white'\n",
    "    mpl.rcParams['text.color'] = COLOR\n",
    "    for i, cas in enumerate(conf_mx):\n",
    "        for j, c in enumerate(cas):\n",
    "            if (c!=0) & (i==j):\n",
    "\n",
    "\n",
    "                plt.text(j-.2, i-.08, c, fontsize=14, fontweight=\"extra bold\")\n",
    "                plt.text(j-.38, i+.23, Percent(norm_conf[i][j]), fontsize=13, fontweight=\"extra bold\")\n",
    "\n",
    "\n",
    "    COLOR = 'black'\n",
    "    mpl.rcParams['text.color'] = COLOR             \n",
    "    for i, cas in enumerate(conf_mx):\n",
    "        for j, c in enumerate(cas):\n",
    "\n",
    "            if (c!=0) & (i!=j):\n",
    "\n",
    "                plt.text(j-.2, i-.08, c, fontsize=14, fontweight=\"extra bold\")\n",
    "                plt.text(j-.38, i+.23, Percent(norm_conf[i][j]), fontsize=13, fontweight=\"extra bold\")  \n",
    "\n",
    "    base_path = \"/home/haptic/ycx/ycx/CM/\"\n",
    "    plt.savefig(base_path + name + \".pdf\", format='pdf',edgecolor='none', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Confusion Matrix\n",
    "y_true=np.array(y_true).reshape(2340)\n",
    "y_pred=np.array(y_pred).reshape(2340)\n",
    "con_mat=confusion_matrix(y_true,y_pred)\n",
    "CM(con_mat,\"EEMD-SHAPEALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QWK\n",
    "qwk=cohen_kappa_score(y_true,y_pred,weights='quadratic')\n",
    "print(qwk)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
